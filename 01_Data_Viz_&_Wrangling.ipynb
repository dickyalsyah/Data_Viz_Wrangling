{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xzE_XWI21zuP",
        "asGJB8Ki2fmr",
        "xYTm69lp25U7",
        "5Q89NV-v5Upz",
        "uos19MkT6tpb",
        "PMDNsRVc7qM7",
        "olcW2W8shH7P",
        "Ssd2XnS3iSrD",
        "Za01chEo0cX4",
        "Qv_Mf9v01as-",
        "akMPKhfH22cA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dickyalsyah/Data_Viz_Wrangling/blob/main/01_Data_Viz_%26_Wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 5 - Read/Export, Join, and Filtering Data\n",
        "---\n",
        "\n",
        "Mentoring Session - Job Preparation Program - Pacmann AI"
      ],
      "metadata": {
        "id": "mWS5ip241pD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please load this library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pV-Ii5mMnqjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1. Merge Transactions Data Across Branches\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4ukEolUB1yrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Descriptions\n",
        "---\n"
      ],
      "metadata": {
        "id": "xzE_XWI21zuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Toko Serba Ada has several branches across the country.\n",
        "- Toko Serba Ada manager wants to merge the transactions data across branches.\n",
        "- Your task is to create a function to join multiple transaction files.\n",
        "- Download the transactions files [here](https://drive.google.com/drive/folders/1bJ5EWEHwx3xXlSLVyUYjjK2D6v_br-hb?usp=sharing)."
      ],
      "metadata": {
        "id": "MPBef9D62hYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detail function\n",
        "---"
      ],
      "metadata": {
        "id": "asGJB8Ki2fmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function called by `import_data`.\n",
        "- The function only needs one input, `filenames` (`list`), a list of transactions data files.\n",
        "- The `import_data` function will join every data listed on the filenames as a Pandas DataFrame."
      ],
      "metadata": {
        "id": "TRxWtTaX2iOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples\n",
        "---"
      ],
      "metadata": {
        "id": "xYTm69lp25U7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input**\n",
        "\n",
        "```python\n",
        "# Masukkan input\n",
        "filenames = [\n",
        "    'branch_A.xlsx',\n",
        "    'branch_B.csv',\n",
        "    'branch_C.csv'\n",
        "]\n",
        "\n",
        "# Import data\n",
        "data = import_data(filenames = filenames)\n",
        "\n",
        "# Validasi hasil\n",
        "print('Data shape:', data.shape)\n",
        "data.head(5)\n",
        "```\n",
        "\n",
        "**Output**\n",
        "```\n",
        "Data shape: (1000, 17)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=10VjyzDyInVbeqb6E5a0AlnU5DuZCx3ef\" />"
      ],
      "metadata": {
        "id": "dZTNOp3227jJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "---\n"
      ],
      "metadata": {
        "id": "jupheDDg4UY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Provide the code for solving the problem\n",
        "- **Make sure your function follows the `Detail Function`**"
      ],
      "metadata": {
        "id": "2_wfnkWT4Wdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl0q4hGyk84P"
      },
      "outputs": [],
      "source": [
        "def import_data(filenames):\n",
        "  \"\"\"\n",
        "  Imports data from multiple files into a single pandas DataFrame.\n",
        "\n",
        "  This function supports .xlsx and .csv file formats. It reads each file into\n",
        "  a DataFrame and appends it to a main DataFrame. If a file has an unsupported\n",
        "  format, the function prints a message and continues with the next file.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize an empty DataFrame\n",
        "  data = pd.DataFrame()\n",
        "\n",
        "  # Loop through all filenames\n",
        "  for filename in filenames:\n",
        "    # Check the file extension\n",
        "    if filename.endswith('.xlsx'):\n",
        "      # If the file is an Excel file, read it into a DataFrame\n",
        "      df = pd.read_excel(filename)\n",
        "    elif filename.endswith('.csv'):\n",
        "      # If the file is a CSV file, read it into a DataFrame\n",
        "      df = pd.read_csv(filename, sep=';')\n",
        "    else:\n",
        "      # If the file has an unsupported format, print a message and skip this file\n",
        "      print(f\"Unsupported file type: {filename}\")\n",
        "      continue\n",
        "\n",
        "    # Append the data to the main DataFrame\n",
        "    data = pd.concat([data, df])\n",
        "\n",
        "  # Return the main DataFrame containing data from all files\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masukkan input\n",
        "filenames = [\n",
        "    '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/branch_A.xlsx',\n",
        "    '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/branch_B.csv',\n",
        "    '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/branch_C.csv'\n",
        "]\n",
        "\n",
        "# Import data\n",
        "data = import_data(filenames = filenames)\n",
        "\n",
        "# Validasi hasil\n",
        "print('Data shape:', data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Grgqhzo2EEwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2. Get the Unwatched Movie\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AcUiUO9e419L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Descriptions\n",
        "---"
      ],
      "metadata": {
        "id": "5Q89NV-v5Upz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You are a data analyst in a movie industry\n",
        "- The product team ask you to recommend something new for a user to watch.\n",
        "- You easily think of recommending the unwatched movies for a specific user Id.\n",
        "- To recommend the unwatched movies nicely in the website, the engineering team needs you to return 3 things\n",
        "  - `movieId`\n",
        "  - `title`\n",
        "  - `genres`\n",
        "- Your task is to **create a function** to return the unwatched movies from a specific user id based on engineering team requirements.\n",
        "- You can download your dataset in [here](https://drive.google.com/drive/folders/1HSa7KStIlOS7rXY5ykwGZR6l9P-AJrKj?usp=sharing).\n",
        "  - `ratings.csv` contains the user activity after watching movies, i.e. give a rating to each movie they watched.\n",
        "  - `movies.csv` contains the movie metadata (movie ID, title, and genre)\n",
        "- The dataset originally comes from **MovieLens**"
      ],
      "metadata": {
        "id": "W6tt_INg5V6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detail function\n",
        "---"
      ],
      "metadata": {
        "id": "uos19MkT6tpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function called `get_unwatched_movie`\n",
        "- The function needs two input\n",
        "  - `userId` (`int`): The targeted user ID\n",
        "  - `config` (`dict`): The configuration files where the engineering team store the user-data and movie metadata. Example\n",
        "\n",
        "  ```python\n",
        "  config = {\n",
        "      'path': {\n",
        "          'user_data': 'ratings.csv',\n",
        "          'metadata': 'movies.csv'\n",
        "      }\n",
        "  }\n",
        "  ```\n",
        "\n",
        "- The function return an output in pandas DataFrame type with `movieId` as an index and two columns of `title` and `genres`."
      ],
      "metadata": {
        "id": "x9fqlTdW6vAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples\n",
        "---"
      ],
      "metadata": {
        "id": "PMDNsRVc7qM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Configuration Variable**\n",
        "\n",
        "```python\n",
        "# Define CONFIG variable\n",
        "CONFIG = {\n",
        "    'path': {\n",
        "        'user_data': 'ratings.csv',\n",
        "        'metadata': 'movies.csv'\n",
        "    }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "kc6xkzW77vAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 1**\n",
        "\n",
        "```python\n",
        "# Cari unwatched data untuk userId = 3\n",
        "unwatched_data = get_unwatched_movie(userId = 3,\n",
        "                                     config = CONFIG)\n",
        "\n",
        "print('Data shape:', unwatched_data.shape)\n",
        "unwatched_data.sample(n=5, random_state=42)\n",
        "```\n",
        "\n",
        "**Output 1**\n",
        "```\n",
        "Data shape: (9703, 2)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=18R0Ym9NplzBnu12hBU10DR8tgFBiQhp6\"/>"
      ],
      "metadata": {
        "id": "A2-pjdaf7617"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 2**\n",
        "\n",
        "```python\n",
        "# Cari unwatched data untuk userId = 10\n",
        "unwatched_data = get_unwatched_movie(userId = 10,\n",
        "                                     config = CONFIG)\n",
        "\n",
        "print('Data shape:', unwatched_data.shape)\n",
        "unwatched_data.sample(n=5, random_state=42)\n",
        "```\n",
        "\n",
        "**Output 2**\n",
        "```\n",
        "Data shape: (9602, 2)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=1m8igXpZ5zS75ioV1tT8gIpLvtrh7TdrK\"/>"
      ],
      "metadata": {
        "id": "ezWDg4vz8ayo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 3**\n",
        "\n",
        "```python\n",
        "# Cari unwatched data untuk userId = 3\n",
        "unwatched_data = get_unwatched_movie(userId = 3,\n",
        "                                     config = CONFIG)\n",
        "\n",
        "print('Data shape:', unwatched_data.shape)\n",
        "unwatched_data.sample(n=5, random_state=42)\n",
        "```\n",
        "\n",
        "**Output 3**\n",
        "```\n",
        "Data shape: (9402, 2)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=1R-BLxcY8Bf3XUxB2Ikf95wafj_1iRNCg\"/>"
      ],
      "metadata": {
        "id": "4huTp6FA8dTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "---\n"
      ],
      "metadata": {
        "id": "0Z-ME-8zAcmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Provide the code for solving the problem\n",
        "- **Make sure your function follows the `Detail Function`**"
      ],
      "metadata": {
        "id": "g-t9K53MAcm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'path': {\n",
        "        'user_data': '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/ratings.csv',\n",
        "        'metadata': '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/movies.csv'\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_unwatched_movie(userId, config):\n",
        "  \"\"\"\n",
        "  Returns a DataFrame of movies that a user has not watched.\n",
        "\n",
        "  This function reads movie and user data from CSV files specified in the config\n",
        "  dictionary, filters out the movies that the user has watched, and returns the\n",
        "  remaining movies.\n",
        "  \"\"\"\n",
        "  # Initialize empty datasets\n",
        "  datasets = {}\n",
        "\n",
        "  # Loop through each item in the config path\n",
        "  for key, value in config['path'].items():\n",
        "      # Read each CSV file and store it in the datasets dictionary\n",
        "      datasets[key] = pd.read_csv(value)\n",
        "\n",
        "  # Get user data and metadata from datasets\n",
        "  user_data = datasets['user_data']\n",
        "  metadata = datasets['metadata']\n",
        "\n",
        "  # Get the movie IDs of movies watched by the user\n",
        "  movie_by_user = user_data[user_data['userId'] == userId]['movieId']\n",
        "\n",
        "  # Filter out watched movies from metadata and set movieId as index\n",
        "  unwatched_movies = metadata[~metadata['movieId'].isin(movie_by_user)]\\\n",
        "                     .set_index('movieId')\n",
        "\n",
        "  return unwatched_movies\n",
        "\n",
        "unwatched_data = get_unwatched_movie(userId = 10, config = CONFIG)\n",
        "print('Data shape:', unwatched_data.shape)\n",
        "unwatched_data.sample(n=5, random_state=42)"
      ],
      "metadata": {
        "id": "v4zhCoX1r-FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3. Get the House Recommendation\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "l8ZTkUY1DXce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Descriptions\n",
        "---"
      ],
      "metadata": {
        "id": "olcW2W8shH7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Assume you work as a Data Analyst in Travelio.\n",
        "- The product team request you to give its users housing recommendations based on their current location and housing preferences.\n",
        "- Please create a function to answer the product team request.\n",
        "- You can find the dataset [here](https://drive.google.com/file/d/1D5phg8q0MiX4lRKlEaBWHT07MoEgEr28/view?usp=sharing).\n",
        "- **Note**: The dataset is scrapped by Pacmann from the Travelio website for educational purposes only."
      ],
      "metadata": {
        "id": "yxZr9PFzhJSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detail function\n",
        "---"
      ],
      "metadata": {
        "id": "Ssd2XnS3iSrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function called by `get_user_recommendation` that return the top-$n$ housing recommendation for a specific user location & preferences sorted by the nearest distance between user location and house location.\n",
        "- The function needs three input, i.e.\n",
        "    - `n` (`int`): the maximum number of recommendation.\n",
        "    - `user_config` (`dict`): the user configuration data. It contains the user preferences and user current location.\n",
        "    - `data_config` (`dict`): the data configuration that contains the housing data path.\n",
        "- The output is a dataframe type with similar data columns to the dataset.\n",
        "---\n",
        "- We filter using 5 preferences, that is\n",
        "  - `property_type`. It should return `apartment` or `house`.\n",
        "  - `size`. It should return houses that is **larger than or equal to** the given `size`.\n",
        "  - `capacity`. It should return houses that is **more than or equal to** the given `capacity`.\n",
        "  - `is_furnished`. It should return `Full Furnished` or `Unfurnished`.\n",
        "  - `yearly_price`. It should return houses that is **less than or equal to** the given `yearly_price` rent\n",
        "- If user fill nothing (`None`), then you should not filter anything.\n",
        "---\n",
        "- Please use the **Haversine** distance to calculate the distance between user and houses.\n",
        "- We intentionally not giving you the Haversine distance formula. Please explore it by yourself."
      ],
      "metadata": {
        "id": "mE5cg8GxiTY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples\n",
        "---"
      ],
      "metadata": {
        "id": "QVyoxliVku2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 1**\n",
        "\n",
        "```python\n",
        "# Define the user data\n",
        "user_config = {\n",
        "    'preferences': {\n",
        "        'property_type': None,\n",
        "        'size': 30.0,\n",
        "        'capacity': 2,\n",
        "        'is_furnished': 'Full Furnished',\n",
        "        'yearly_price': 50000000\n",
        "    },\n",
        "    'location': {\n",
        "        # Dekat Bintaro Plaza\n",
        "        'latitude': -6.2734,\n",
        "        'longitude': 106.7364\n",
        "    }\n",
        "}\n",
        "\n",
        "data_config = {\n",
        "    'path': 'travelio_dki_jakarta.csv'\n",
        "}\n",
        "\n",
        "# Run the function\n",
        "user_recommendation = get_user_recommendation(n = 10,\n",
        "                                              user_config = user_config,\n",
        "                                              data_config = data_config)\n",
        "\n",
        "# Validate\n",
        "print('Data Shape:', user_recommendation.shape)\n",
        "user_recommendation\n",
        "```\n",
        "\n",
        "**Output 1**\n",
        "```\n",
        "Data Shape: (10, 16)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=1Ek8VjhgOqWh18T1zEvn0b5zZIKlMt1wG\"/>"
      ],
      "metadata": {
        "id": "4OdE7AAzlAP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 2**\n",
        "\n",
        "```python\n",
        "# Define the user data\n",
        "user_config = {\n",
        "    'preferences': {\n",
        "        'property_type': None,\n",
        "        'size': 45.0,\n",
        "        'capacity': 4,\n",
        "        'is_furnished': None,\n",
        "        'yearly_price': 25000000\n",
        "    },\n",
        "    'location': {\n",
        "        # Dekat Monumen Nasional (Monas)\n",
        "        'latitude': -6.1792,\n",
        "        'longitude': 106.8265\n",
        "    }\n",
        "}\n",
        "\n",
        "data_config = {\n",
        "    'path': 'travelio_dki_jakarta.csv'\n",
        "}\n",
        "\n",
        "# Run the function\n",
        "user_recommendation = get_user_recommendation(n = 10,\n",
        "                                              user_config = user_config,\n",
        "                                              data_config = data_config)\n",
        "\n",
        "# Validate\n",
        "print('Data Shape:', user_recommendation.shape)\n",
        "user_recommendation\n",
        "```\n",
        "\n",
        "**Output 2**\n",
        "```\n",
        "Data Shape: (10, 16)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=14eIe-BjfjTM53Y3m9ObdoQ2nKVWgUGiY\"/>"
      ],
      "metadata": {
        "id": "zYjtpQ_HlBLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 3**\n",
        "\n",
        "```python\n",
        "# Define the user data\n",
        "user_config = {\n",
        "    'preferences': {\n",
        "        'property_type': None,\n",
        "        'size': 60.0,\n",
        "        'capacity': 4,\n",
        "        'is_furnished': None,\n",
        "        'yearly_price': 25000000\n",
        "    },\n",
        "    'location': {\n",
        "        # Dekat Kota Tua Jakarta\n",
        "        'latitude': -6.1378,\n",
        "        'longitude': 106.8144\n",
        "    }\n",
        "}\n",
        "\n",
        "data_config = {\n",
        "    'path': 'travelio_dki_jakarta.csv'\n",
        "}\n",
        "\n",
        "# Run the function\n",
        "user_recommendation = get_user_recommendation(n = 10,\n",
        "                                              user_config = user_config,\n",
        "                                              data_config = data_config)\n",
        "\n",
        "# Validate\n",
        "print('Data Shape:', user_recommendation.shape)\n",
        "user_recommendation\n",
        "```\n",
        "\n",
        "**Output 3**\n",
        "```\n",
        "Data Shape: (6, 16)\n",
        "```\n",
        "<img src=\"https://drive.google.com/uc?id=1WAjuLElzpxuECoh8ArhD2XeWEj1T3blk\"/>"
      ],
      "metadata": {
        "id": "QjkWBi07lB6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "---"
      ],
      "metadata": {
        "id": "4HleIt4RmrZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Provide the code for solving the problem\n",
        "- **Make sure your function follows the `Detail Function`**"
      ],
      "metadata": {
        "id": "ygTl_yizmtaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class SearchProperty():\n",
        "  \"\"\"\n",
        "  A class used to filter properties based on user preferences.\n",
        "\n",
        "  ...\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "  data_ : DataFrame\n",
        "      a pandas DataFrame that stores the property data\n",
        "\n",
        "  Methods\n",
        "  -------\n",
        "  load_data(func):\n",
        "      Decorator function to load property data from a CSV file.\n",
        "  haversine(lat1, lon1, lat2, lon2):\n",
        "      Calculates the haversine distance between two points on the Earth's surface.\n",
        "  get_user_recommendation(n, user_config, data_config):\n",
        "      Returns a DataFrame of recommended properties based on user preferences.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Constructs all the necessary attributes for the PropertyFilter object.\n",
        "    \"\"\"\n",
        "    # Initializes an empty DataFrame to store property data\n",
        "    self.data_ = None\n",
        "\n",
        "  def load_data(func):\n",
        "    \"\"\"\n",
        "    Decorator function to load property data from a CSV file.\n",
        "    \"\"\"\n",
        "    def wrapper(self, n, user_config, data_config):\n",
        "      \"\"\"\n",
        "      Wrapper function to load data and call the decorated function.\n",
        "      \"\"\"\n",
        "      # Get the input path from the data configuration\n",
        "      input_path = data_config['path']\n",
        "\n",
        "      try:\n",
        "        # Try to read the CSV file\n",
        "        self.data_ = pd.read_csv(input_path)\n",
        "      except FileNotFoundError:\n",
        "        # Raise an error if the file is not found\n",
        "        raise FileNotFoundError(\"Input file not found.\")\n",
        "\n",
        "      if self.data_.empty:\n",
        "        # Check if the loaded data is empty\n",
        "        raise ValueError(\"Loaded data is empty.\")\n",
        "\n",
        "      # Call the decorated function and return its result\n",
        "      return func(self, n, user_config, data_config)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "  def haversine(self, lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculates the haversine distance between two points on the Earth's surface.\n",
        "\n",
        "    Following is the formula:\n",
        "      a = sin²(∆𝜑/2) + cos(𝜑₁) * cos(𝜑₂) * √sin(∆ƛ/2)\n",
        "      d = 6371 * (2 * atan2(√a), √(1 - a))\n",
        "\n",
        "    \"\"\"\n",
        "    r = 6371  # Radius of the earth in kilometers\n",
        "\n",
        "    # Convert all coordinates from degrees to radians\n",
        "    phi1 = math.radians(lat1)\n",
        "    phi2 = math.radians(lat2)\n",
        "    delta_phi = math.radians(lat2 - lat1)\n",
        "    delta_lambda = math.radians(lon2 - lon1)\n",
        "\n",
        "    # Calculate haversine distance\n",
        "    a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * \\\n",
        "        math.sin(delta_lambda / 2)**2\n",
        "    distance = r * (2 * math.atan2(math.sqrt(a), math.sqrt(1 - a)))\n",
        "    return distance\n",
        "\n",
        "  @load_data\n",
        "  def get_user_recommendation(self, n, user_config, data_config):\n",
        "    \"\"\"\n",
        "    Returns a DataFrame of recommended properties based on user preferences.\n",
        "\n",
        "    This method applies various filters to self.data_ based on user preferences,\n",
        "    calculates the haversine distance from each property to the user's location,\n",
        "    sorts the properties by distance, and returns the top n recommendations.\n",
        "    \"\"\"\n",
        "    # Store original columns for later use\n",
        "    original_columns = self.data_.columns.tolist()\n",
        "\n",
        "    # Get user preferences from config\n",
        "    preferences = user_config['preferences']\n",
        "\n",
        "    # Iterate from the preferences data\n",
        "    for key, val in preferences.items():\n",
        "      if val is not None:\n",
        "        # Apply filters based on user preferences\n",
        "        if key == 'property_type':\n",
        "          self.data_ = self.data_[self.data_[key] == val]\n",
        "        elif key == 'size' or key == 'capacity':\n",
        "          self.data_ = self.data_[self.data_[key] >= val]\n",
        "        elif key == 'is_furnished':\n",
        "          self.data_ = self.data_[self.data_[key] == val]\n",
        "        elif key == 'yearly_price':\n",
        "          self.data_ = self.data_[self.data_[key] <= val]\n",
        "        else:\n",
        "          self.data_ = self.data_[self.data_[key] == val]\n",
        "\n",
        "    lat_min, lat_max = self.data_['latitude'].min(), self.data_['latitude'].max()\n",
        "    lon_min, lon_max = self.data_['longitude'].min(), self.data_['longitude'].max()\n",
        "\n",
        "    # Get user location based on config data\n",
        "    user_location = (user_config['location']['latitude'],\n",
        "                    user_config['location']['longitude'])\n",
        "\n",
        "    if (user_location[0] <= lat_min or user_location[0] >= lat_max) and \\\n",
        "      (user_location[1] <= lon_min or user_location[1] >= lon_max):\n",
        "      raise ValueError(\"Your location is far from the data\")\n",
        "\n",
        "    else:\n",
        "      # Make a new col distance based on haversine function\n",
        "      self.data_['distance'] = self.data_.apply(lambda row:\n",
        "                        self.haversine(user_location[0], user_location[1],\n",
        "                        row['latitude'], row['longitude']), axis=1)\n",
        "\n",
        "      # Sort dataframe with Ascending distance column\n",
        "      self.data_ = self.data_.sort_values('distance')\n",
        "\n",
        "      # Return DataFrame result with length based on size n parameter\n",
        "      result = self.data_[original_columns].head(n)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "liakKidM_Aru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_config = {\n",
        "    'preferences': {\n",
        "        'property_type': None,\n",
        "        'size': 45.0,\n",
        "        'capacity': 4,\n",
        "        'is_furnished': None,\n",
        "        'yearly_price': 25000000\n",
        "    },\n",
        "    'location': {\n",
        "        # Dekat Monumen Nasional (Monas)\n",
        "        'latitude': -6.1792,\n",
        "        'longitude': 106.8265\n",
        "    }\n",
        "}\n",
        "\n",
        "data_config = {\n",
        "    'path': '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/travelio_dki_jakarta.csv'\n",
        "}\n",
        "\n",
        "# Run the function\n",
        "property = SearchProperty()\n",
        "user_recommendation = property.get_user_recommendation(n = 10,\n",
        "                                              user_config = user_config,\n",
        "                                              data_config = data_config)\n",
        "\n",
        "# Validate\n",
        "print('Data Shape:', user_recommendation.shape)\n",
        "user_recommendation"
      ],
      "metadata": {
        "id": "vHvzAvZBOytg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4. Export the Promising State\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "r44bj8r2m5Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Descriptions\n",
        "---\n"
      ],
      "metadata": {
        "id": "Za01chEo0cX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Assumed you are a data analyst in Amazon.\n",
        "- Your supervisor ask you to export a promising state sales data based on its market share to a .csv files, thus each state representatives can analyst the sales data further.\n",
        "- A promising state is a state that has its market share bigger or equal to a specified threshold.\n",
        "- The market share of a specific state is defined as number of order on a specific state / total order.\n",
        "- Write a function to help your supervisor!\n",
        "- Download your data in [here](https://drive.google.com/file/d/1oRAPo7ZST2i_pHAIWP2_KoLraniUwyME/view?usp=sharing).\n",
        "- The actual data source is in [here](https://www.kaggle.com/datasets/thedevastator/unlock-profits-with-e-commerce-sales-data?select=Amazon+Sale+Report.csv)."
      ],
      "metadata": {
        "id": "NfqpPT5F0dbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detail function\n",
        "---"
      ],
      "metadata": {
        "id": "Qv_Mf9v01as-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function called by `export_promising_state`\n",
        "- This function needs two inputs\n",
        "  - `config_file` (`dict`) contains the input and output path\n",
        "  - `thresh` (`float`) contains the given market share threshold.\n",
        "- This function returns nothing.\n",
        "- If you cannot find any promising state based on the given threshold, then print `No promising state`.\n",
        "- If you can find promising state,\n",
        "  - First, drop column `index` and `Unnamed: 22` from the promising data.\n",
        "  - Save the promising data with format: `folder_path` + `state-name` + `-sales-reports.csv`, e.g.: `sales_data/telangana-sales-reports.csv`\n",
        "  - Write the prompt after successfully exporting data that includes the state market share and state sales data shape."
      ],
      "metadata": {
        "id": "gwnE4aS81bc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples\n",
        "---"
      ],
      "metadata": {
        "id": "akMPKhfH22cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Configuration Variable**\n",
        "\n",
        "```python\n",
        "# Define CONFIG variable\n",
        "config_file = {\n",
        "    'path': {\n",
        "        'input': 'Amazon Sale Report.csv',\n",
        "        'output': 'sales_data/'\n",
        "    }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "9hG0MZ8-3Jam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 1**\n",
        "\n",
        "```python\n",
        "# Input 1\n",
        "export_promising_state(config_file = config_file,\n",
        "                       thresh = 0.10)\n",
        "```\n",
        "\n",
        "**Output 1**\n",
        "```\n",
        "Data of state \"karnataka\" was successfully exported into \"sales_data/karnataka-sales-reports.csv\"\n",
        "  - State market share : 13.43 %\n",
        "  - Data shape         : (17326, 22)\n",
        "\n",
        "Data of state \"maharashtra\" was successfully exported into \"sales_data/maharashtra-sales-reports.csv\"\n",
        "  - State market share : 17.26 %\n",
        "  - Data shape         : (22260, 22)\n",
        "```\n",
        "\n",
        "Example of the created files: <br>\n",
        "<img src=\"https://drive.google.com/uc?id=1C1r8SKoRHbKX0upPl5VDrzuf4Mi0joiC\"/>"
      ],
      "metadata": {
        "id": "dBZudV3I3Pb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 2**\n",
        "\n",
        "```python\n",
        "# Input 2\n",
        "export_promising_state(config_file = config_file,\n",
        "                       thresh = 0.05)\n",
        "```\n",
        "\n",
        "**Output 2**\n",
        "```\n",
        "Data of state \"telangana\" was successfully exported into \"sales_data/telangana-sales-reports.csv\"\n",
        "  - State market share : 8.78 %\n",
        "  - Data shape         : (11330, 22)\n",
        "\n",
        "Data of state \"kerala\" was successfully exported into \"sales_data/kerala-sales-reports.csv\"\n",
        "  - State market share : 5.11 %\n",
        "  - Data shape         : (6585, 22)\n",
        "\n",
        "Data of state \"delhi\" was successfully exported into \"sales_data/delhi-sales-reports.csv\"\n",
        "  - State market share : 5.40 %\n",
        "  - Data shape         : (6967, 22)\n",
        "\n",
        "Data of state \"uttar pradesh\" was successfully exported into \"sales_data/uttar pradesh-sales-reports.csv\"\n",
        "  - State market share : 8.25 %\n",
        "  - Data shape         : (10638, 22)\n",
        "\n",
        "Data of state \"karnataka\" was successfully exported into \"sales_data/karnataka-sales-reports.csv\"\n",
        "  - State market share : 13.43 %\n",
        "  - Data shape         : (17326, 22)\n",
        "\n",
        "Data of state \"tamil nadu\" was successfully exported into \"sales_data/tamil nadu-sales-reports.csv\"\n",
        "  - State market share : 8.90 %\n",
        "  - Data shape         : (11483, 22)\n",
        "\n",
        "Data of state \"maharashtra\" was successfully exported into \"sales_data/maharashtra-sales-reports.csv\"\n",
        "  - State market share : 17.26 %\n",
        "  - Data shape         : (22260, 22)\n",
        "```\n",
        "\n",
        "Example of the created files: <br>\n",
        "<img src=\"https://drive.google.com/uc?id=1ujeDK87N4MLk1_9Uew4lkIeFA81_DtDw\"/>"
      ],
      "metadata": {
        "id": "PTRSlJ5q3Tll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Input 3**\n",
        "\n",
        "```python\n",
        "# Input 3\n",
        "export_promising_state(config_file = config_file,\n",
        "                       thresh = 0.4)\n",
        "```\n",
        "\n",
        "**Output 3**\n",
        "```\n",
        "No promising state\n",
        "```\n",
        "<img src=\"\"/>"
      ],
      "metadata": {
        "id": "zffc2mVO3VZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "---\n"
      ],
      "metadata": {
        "id": "Vd_cKbpD4LC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Provide the code for solving the problem\n",
        "- **Make sure your function follows the `Detail Function`**"
      ],
      "metadata": {
        "id": "UarFLbE54LC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExportSalesData():\n",
        "  \"\"\"\n",
        "  A class to handle the export of sales data in each state based on treshold\n",
        "  market share defined.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initialize the class with empty data.\n",
        "    \"\"\"\n",
        "    self.data_ = None\n",
        "    self.state_order_ = None\n",
        "\n",
        "  def load_data(func):\n",
        "    \"\"\"\n",
        "    Decorator function to load data from a CSV file.\n",
        "\n",
        "    This function is designed to be used as a decorator for methods in a class.\n",
        "    The decorated method should have a 'self' parameter (reference to\n",
        "    the class instance) and a 'config_file' parameter (dictionary containing\n",
        "    configuration options).\n",
        "\n",
        "    The decorator reads a CSV file specified in the 'config_file' dictionary,\n",
        "    loads the data into a pandas DataFrame, and assigns it to 'self.data_'.\n",
        "\n",
        "    If the CSV file is not found or the loaded data is empty, an error is\n",
        "    raised.\n",
        "    \"\"\"\n",
        "    def wrapper(self, config_file):\n",
        "      \"\"\"\n",
        "      Wrapper function to load data and call the decorated function.\n",
        "\n",
        "      This function reads the input path from the 'config_file' dictionary,\n",
        "      tries to load the data from a CSV file at that path, and checks if the\n",
        "      loaded data is empty. If everything is fine, it calls the decorated\n",
        "      function.\n",
        "      \"\"\"\n",
        "      # Get the input path from the config file\n",
        "      input_path = config_file['path']['input']\n",
        "\n",
        "      try:\n",
        "        # Try to read the CSV file\n",
        "        self.data_ = pd.read_csv(input_path)\n",
        "      except FileNotFoundError:\n",
        "        # Raise an error if the file is not found\n",
        "        raise FileNotFoundError(\"Input file not found.\")\n",
        "\n",
        "      if self.data_.empty:\n",
        "        # Check if the loaded data is empty\n",
        "        raise ValueError(\"Loaded data is empty.\")\n",
        "\n",
        "      # Call the decorated function and return its result\n",
        "      return func(self, config_file)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "  @load_data\n",
        "  def calculate_market_share(self, config_file):\n",
        "    \"\"\"\n",
        "    Calculate the market share for each state.\n",
        "    Market share based on size of order in a state divide total order\n",
        "    in the data.\n",
        "    \"\"\"\n",
        "    # Group by state and calculate the market share\n",
        "    self.state_order_ = self.data_.groupby('ship-state').size().\\\n",
        "                       reset_index(name='count')\n",
        "    total_order = len(self.data_)\n",
        "    # Add new column to calculate market share\n",
        "    self.state_order_['market_share'] = self.state_order_['count'] / total_order\n",
        "\n",
        "  def filter_promising_states(self, config_file, thresh):\n",
        "    \"\"\"\n",
        "    Filter states that have a market share greater than a threshold.\n",
        "    \"\"\"\n",
        "    # Load data and calculate market share if they're not done yet\n",
        "    if self.state_order_ is None:\n",
        "      # self.load_data(config_file)\n",
        "      self.calculate_market_share(config_file)\n",
        "\n",
        "    # Return states with market share greater than the threshold\n",
        "    return self.state_order_[self.state_order_['market_share'] > thresh]\n",
        "\n",
        "  def export_promising_states(self, config_file, thresh):\n",
        "    \"\"\"\n",
        "    Export sales data of promising states to CSV files.\n",
        "    \"\"\"\n",
        "    # Get promising states\n",
        "    filtered_data = self.filter_promising_states(config_file, thresh)\n",
        "\n",
        "    # Check if there are any promising states\n",
        "    if filtered_data.empty:\n",
        "      print(\"No Promising State\")\n",
        "      pass\n",
        "\n",
        "    else:\n",
        "      # Drop unnecessary columns\n",
        "      self.data_.drop(columns=['index', 'Unnamed: 22'], inplace=True)\n",
        "      # Get the output folder from the config file\n",
        "      output_folder = config_file['path']['output']\n",
        "\n",
        "      # Export sales data to a CSV file and print summary of each promising state\n",
        "      for id, row in filtered_data.iterrows():\n",
        "        state_name = row['ship-state'].lower()\n",
        "        state_data = self.data_[self.data_['ship-state'].str.lower() == state_name]\n",
        "        output_filename = f\"{output_folder}{state_name}-sales-reports.csv\"\n",
        "        state_data.to_csv(output_filename, index=False)\n",
        "        print(f'Data of state \"{state_name}\" was successfully exported into \\\n",
        "              \"{output_filename}\"')\n",
        "        print(f\" - State market share : {row['market_share']:.2%}\")\n",
        "        print(f\" - Data shape         : {state_data.shape}\\n\")"
      ],
      "metadata": {
        "id": "HGKq-kaxmfXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CONFIG variable\n",
        "config_file = {\n",
        "    'path': {\n",
        "        'input': '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/Dataset/Amazon Sale Report.csv',\n",
        "        'output': '/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/sales_data/'\n",
        "    }\n",
        "}\n",
        "\n",
        "report = ExportSalesData()\n",
        "report.export_promising_states(config_file, 0.05)"
      ],
      "metadata": {
        "id": "ITXLvhdnna32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Pacman/Data Wrangling & Visualization/Week 5/sales_data/delhi-sales-reports.csv\")\n",
        "data['ship-state'].value_counts()"
      ],
      "metadata": {
        "id": "IHwd2P8717K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb6CrtQVxuoP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}